# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gYqxyfgzdlbB9Vjt9f7UZyWCRYR_gkuQ
"""

#Building logistic regression model

#pytorch is like advanced version of np arrays (bcs its used for computation) and is mainly used for deep learning

import torch
import torchvision
from torchvision.datasets import MNIST
import matplotlib.pyplot as plt

#downloading MNIST(numbers list) data:
dataset = MNIST(root = 'data', download=True)

len(dataset)

#Now we will download the test part of this MNIST folder:
test_dataset = MNIST(root='data', train=False)

len(test_dataset)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

image, label = dataset[59999]
plt.imshow(image, cmap = 'gray')
print('label:' , label)

import torchvision.transforms as transforms

dataset = MNIST(root='data', train=True, transform=transforms.ToTensor())

len(dataset)

img, label = dataset[0]
print(img.shape)

#splitting training and validation data in 50k:10k ratio
from torch.utils.data import random_split
train_dataset, validation_dataset = random_split(dataset, [50000,10000])

# Create data loaders
from torch.utils.data import DataLoader
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
validation_loader = DataLoader(validation_dataset, batch_size=64)

import torch.nn as nn
input_size = 28*28 #we are making this 2d array into a 1d bcs it wont process as 28x28 array
num_class = 10 #10 possible outputs
import torch.nn as nn

model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(784, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)

  #creating the model

model.weight #are both randomly assigned for now

img.shape

#but we gotta reshape it:
img.reshape(784).shape

import torch.optim as optim
#creating a loss fuunction used for classification:
loss_func = nn.CrossEntropyLoss()
#creating an optimizer that will change parameters for better performance
optimizer = optim.SGD(model.parameters(), lr=0.01)   #lr=learning rate

class Trainer:
    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader):
        self.model = model
        self.loss_fn = loss_fn
        self.optimizer = optimizer
        self.train_loader = train_loader
        self.val_loader = val_loader

    def train(self, epochs):
        for epoch in range(epochs):
            self.model.train()
            total_train_loss = 0

            for images, labels in self.train_loader:
                self.optimizer.zero_grad()
                outputs = self.model(images)
                loss = self.loss_fn(outputs, labels) #compares outputs with actual labels
                loss.backward()
                self.optimizer.step()  #will actually tune parameters
                total_train_loss += loss.item()  #to see how much model is improving

            val_loss, val_accuracy = self.validate()
            print(f"Epoch {epoch+1}: Train Loss = {total_train_loss:.4f} | Val Loss = {val_loss:.4f} | Val Accuracy = {val_accuracy:.2f}%")

    def validate(self):
        self.model.eval()
        total_val_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in self.val_loader:
                outputs = self.model(images)
                loss = self.loss_fn(outputs, labels)
                total_val_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                correct += (predicted == labels).sum().item()
                total += labels.size(0)

        accuracy = 100 * correct / total
        return total_val_loss, accuracy

Trainer( model, loss_func, optimizer, train_loader, validation_loader)

trainer = Trainer( model, loss_func, optimizer, train_loader, validation_loader)

trainer.train(epochs=5)

#NEW
dataset1 = MNIST(root='data', train=False, transform=transforms.ToTensor())

#dataloader for the test set:
test_loader = DataLoader(dataset1, batch_size=64)

def test_model(model, test_loader, loss_func):
    model.eval()  # set model to evaluation mode
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():  # disable gradient tracking for testing
        for images, labels in test_loader:
            outputs = model(images)
            loss = loss_func(outputs, labels)
            total_loss += loss.item()

            # Get predicted class by finding max logit
            _, predicted = torch.max(outputs, dim=1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    accuracy = 100 * correct / total
    print(f"Test Loss: {total_loss:.4f} | Test Accuracy: {accuracy:.2f}%")

# Assuming model is trained and loss_fn is defined
test_model(model, test_loader, loss_func)

